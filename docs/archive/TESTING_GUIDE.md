# Testing Guide - Blockchain Forensics Platform

## ğŸ“‹ Ãœbersicht

Dieses Projekt verwendet eine **state-of-the-art Test-Struktur** mit klarer Trennung zwischen:
- **Unit-Tests**: Schnell, isoliert, keine externen Dependencies
- **Integration-Tests**: Mit DB, Redis, APIs
- **E2E-Tests**: VollstÃ¤ndige User-Journeys
- **Security-Tests**: OWASP, Penetration, Dependency-Checks

## ğŸ—ï¸ Test-Struktur

### Backend (Python/pytest)

```
backend/tests/
â”œâ”€â”€ unit/                           # Unit-Tests (schnell, isoliert)
â”‚   â”œâ”€â”€ models/                     # Model-Tests
â”‚   â””â”€â”€ services/                   # Service-Tests
â”œâ”€â”€ integration/                    # Integration-Tests
â”‚   â”œâ”€â”€ api/                        # API-Endpoint-Tests
â”‚   â”‚   â”œâ”€â”€ test_agent_consolidated.py      # AI-Agent-Tests
â”‚   â”‚   â”œâ”€â”€ test_alerts_consolidated.py     # Alert-Engine-Tests
â”‚   â”‚   â”œâ”€â”€ test_risk_consolidated.py       # Risk-Engine-Tests
â”‚   â”‚   â”œâ”€â”€ test_orgs_api.py                # Organizations
â”‚   â”‚   â”œâ”€â”€ test_chat_api.py                # Chat
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ adapters/                   # Chain-Adapter-Tests
â”‚   â”‚   â”œâ”€â”€ test_bitcoin_adapter.py
â”‚   â”‚   â”œâ”€â”€ test_solana_adapter.py
â”‚   â”‚   â””â”€â”€ test_l2_adapters.py
â”‚   â””â”€â”€ workers/                    # Worker-Tests
â”‚       â””â”€â”€ test_integration_workers.py
â”œâ”€â”€ e2e/                            # End-to-End-Tests
â”‚   â””â”€â”€ test_enterprise_integration.py
â”œâ”€â”€ security/                       # Security-Tests
â”‚   â”œâ”€â”€ test_api_security.py
â”‚   â”œâ”€â”€ test_authentication.py
â”‚   â”œâ”€â”€ test_crypto_security.py
â”‚   â”œâ”€â”€ test_sql_injection.py
â”‚   â””â”€â”€ test_xss_csrf.py
â””â”€â”€ fixtures/                       # Shared Test-Fixtures
```

### Frontend (TypeScript/Vitest/Playwright)

```
frontend/tests/
â”œâ”€â”€ unit/                           # Vitest Unit-Tests
â”‚   â”œâ”€â”€ components/                 # Component-Tests
â”‚   â””â”€â”€ utils/                      # Utility-Tests
â”œâ”€â”€ integration/                    # Vitest Integration-Tests
â”‚   â”œâ”€â”€ ai-agent-stream.spec.tsx   # AI-Agent-Integration
â”‚   â”œâ”€â”€ patterns-page.spec.tsx     # Patterns-Page
â”‚   â””â”€â”€ patterns-buttons.spec.tsx  # Patterns-Buttons
â””â”€â”€ e2e/                            # Playwright E2E-Tests
    â”œâ”€â”€ chat-widget.spec.ts         # Chat-Widget
    â”œâ”€â”€ investigator-deeplink.spec.ts
    â”œâ”€â”€ consent/                    # Consent-Management
    â”œâ”€â”€ health/                     # Health-Checks
    â”œâ”€â”€ metrics/                    # Web-Vitals
    â””â”€â”€ navigation/                 # Navigation-Tests
```

## ğŸš€ Tests ausfÃ¼hren

### Alle Tests (Master-Script)

```bash
# Alle Tests mit einem Befehl
./run-all-tests.sh

# Mit Security-Scans
RUN_SECURITY_SCANS=true ./run-all-tests.sh
```

### Backend-Tests

```bash
cd backend

# Alle Tests
pytest tests/ -v

# Nur Unit-Tests (schnell)
pytest tests/unit -v -m unit

# Nur Integration-Tests
pytest tests/integration -v -m integration

# Nur Security-Tests
pytest tests/security -v -m security

# Spezifische Kategorien
pytest tests -v -m agent          # AI-Agent-Tests
pytest tests -v -m alert          # Alert-Engine-Tests
pytest tests -v -m risk           # Risk-Engine-Tests
pytest tests -v -m adapter        # Chain-Adapter-Tests
pytest tests -v -m bridge         # Bridge-Detection-Tests
pytest tests -v -m clustering     # Clustering-Tests

# Mit Coverage
pytest tests/ -v --cov=app --cov-report=html --cov-report=term-missing

# Langsame Tests Ã¼berspringen
pytest tests/ -v -m "not slow"

# Nur fehlgeschlagene Tests wiederholen
pytest tests/ -v --lf
```

### Frontend-Tests

```bash
cd frontend

# Vitest Unit & Integration Tests
npm run test                # Einmalig
npm run test:ui             # Mit UI

# Playwright E2E Tests
npm run test:e2e            # Alle Browser
npm run test:e2e:ui         # Mit UI

# Spezifische Tests
npm run test -- ai-agent-stream.spec.tsx
npx playwright test chat-widget.spec.ts
```

## ğŸ·ï¸ Test-Marker (Backend)

Pytest-Marker fÃ¼r Filterung und Organisation:

| Marker | Beschreibung | Beispiel |
|--------|--------------|----------|
| `unit` | Schnelle Unit-Tests ohne Dependencies | `@pytest.mark.unit` |
| `integration` | Tests mit DB, Redis, etc. | `@pytest.mark.integration` |
| `e2e` | End-to-End voller Stack | `@pytest.mark.e2e` |
| `slow` | Tests > 5 Sekunden | `@pytest.mark.slow` |
| `security` | Security-spezifische Tests | `@pytest.mark.security` |
| `api` | API-Endpoint-Tests | `@pytest.mark.api` |
| `adapter` | Chain-Adapter-Tests | `@pytest.mark.adapter` |
| `agent` | AI-Agent-Tests | `@pytest.mark.agent` |
| `alert` | Alert-Engine-Tests | `@pytest.mark.alert` |
| `risk` | Risk-Engine-Tests | `@pytest.mark.risk` |
| `bridge` | Bridge-Detection-Tests | `@pytest.mark.bridge` |
| `clustering` | Clustering/ML-Tests | `@pytest.mark.clustering` |

Verwendung:
```python
import pytest

@pytest.mark.unit
def test_my_function():
    assert True

@pytest.mark.integration
@pytest.mark.api
def test_api_endpoint():
    assert True

@pytest.mark.slow
@pytest.mark.e2e
def test_full_workflow():
    assert True
```

## ğŸ“Š Coverage-Ziele

- **Backend**: â‰¥80% Line Coverage
- **Frontend**: â‰¥70% Line Coverage
- **Kritische Module** (Security, Auth): â‰¥90%

Coverage-Reports:
```bash
# Backend
cd backend
pytest tests/ --cov=app --cov-report=html
open htmlcov/index.html

# Frontend
cd frontend
npm run test -- --coverage
open coverage/index.html
```

## ğŸ”’ Security-Tests

```bash
# VollstÃ¤ndiger Security-Audit
make security-scan

# Einzelne Tools
cd backend
bandit -r app/ -f txt              # SAST
safety check                       # Dependencies
semgrep --config=.semgrep.yml      # Pattern-basiert
detect-secrets scan --all-files    # Secrets
```

## ğŸ› Debugging

### Backend

```python
# Mit pdb debuggen
pytest tests/test_file.py -v -s --pdb

# Nur fehlgeschlagene Tests
pytest tests/ --lf

# Mit ausfÃ¼hrlichem Output
pytest tests/ -vv --tb=long

# Specific test function
pytest tests/test_file.py::test_function_name -v
```

### Frontend

```bash
# Vitest Debugging
npm run test:ui                    # Mit Browser UI

# Playwright Debugging
npx playwright test --debug        # Mit Inspector
npx playwright test --headed       # Mit sichtbarem Browser
npx playwright test --ui           # Mit Test-UI
```

## ğŸ“ Test-Best-Practices

### 1. Test-Benennung

```python
# âœ… Gut: Beschreibend und klar
def test_user_can_login_with_valid_credentials():
    pass

def test_api_returns_404_for_nonexistent_resource():
    pass

# âŒ Schlecht: Unklar
def test_1():
    pass

def test_stuff():
    pass
```

### 2. Arrange-Act-Assert Pattern

```python
def test_risk_score_calculation():
    # Arrange: Setup
    address = "0x742d35Cc6634C0532925a3b8D807A69F8e4F41d4"
    expected_score = 0.75
    
    # Act: Execute
    result = calculate_risk_score(address)
    
    # Assert: Verify
    assert result == expected_score
```

### 3. Fixtures verwenden

```python
@pytest.fixture
def test_client():
    return TestClient(app)

@pytest.fixture
def sample_address():
    return "0x742d35Cc6634C0532925a3b8D807A69F8e4F41d4"

def test_with_fixtures(test_client, sample_address):
    response = test_client.get(f"/api/v1/risk?address={sample_address}")
    assert response.status_code == 200
```

### 4. Parametrisierte Tests

```python
@pytest.mark.parametrize("address,expected_valid", [
    ("0x742d35Cc6634C0532925a3b8D807A69F8e4F41d4", True),
    ("invalid", False),
    ("0x123", False),
])
def test_address_validation(address, expected_valid):
    assert is_valid_address(address) == expected_valid
```

### 5. Mocking externe Services

```python
from unittest.mock import patch, MagicMock

@patch('app.services.external_api.fetch_data')
def test_with_mocked_api(mock_fetch):
    mock_fetch.return_value = {"result": "mocked"}
    result = my_function_that_uses_api()
    assert result == {"result": "mocked"}
    mock_fetch.assert_called_once()
```

## ğŸ”„ CI/CD Integration

Tests werden automatisch in GitHub Actions ausgefÃ¼hrt:

```yaml
# .github/workflows/ci-cd.yml
- name: Run Backend Tests
  run: |
    cd backend
    pytest tests/ -v --cov=app --cov-report=xml

- name: Run Frontend Tests
  run: |
    cd frontend
    npm run test
    npm run test:e2e
```

## ğŸ“š Konsolidierte Tests

Folgende Tests wurden konsolidiert fÃ¼r bessere Wartbarkeit:

### AI-Agent-Tests â†’ `test_agent_consolidated.py`
Vereint: `test_agent_api_tools.py`, `test_agent_health.py`, `test_agent_tools_api.py`, etc.

### Alert-Tests â†’ `test_alerts_consolidated.py`
Vereint: `test_alert_engine_suppression.py`, `test_alerts_kpis_endpoint.py`, etc.

### Risk-Tests â†’ `test_risk_consolidated.py`
Vereint: `test_risk_api.py`, `test_risk_weights_api.py`, `test_rule_engine.py`, etc.

## â“ Troubleshooting

### "No module named 'app'"
```bash
# Sicherstellen, dass PYTHONPATH gesetzt ist
cd backend
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
pytest tests/
```

### Playwright-Timeout
```bash
# Timeout erhÃ¶hen
npx playwright test --timeout=60000
```

### Coverage zu niedrig
```bash
# Detaillierte Coverage-Analyse
pytest tests/ --cov=app --cov-report=term-missing
# Zeigt fehlende Zeilen
```

## ğŸ¯ Quick Reference

```bash
# Schnelltest (nur Unit)
cd backend && pytest tests/unit -v -m unit

# VollstÃ¤ndiger Test mit Coverage
./run-all-tests.sh

# Nur geÃ¤nderte Tests
cd backend && pytest tests/ -v --testmon

# Frontend Watch-Mode
cd frontend && npm run test -- --watch

# E2E mit UI
cd frontend && npm run test:e2e:ui
```

## ğŸ“ Support

Bei Fragen oder Problemen:
1. Siehe `TEST_ANALYSIS.md` fÃ¼r detaillierte Struktur-Analyse
2. PrÃ¼fe CI-Logs in GitHub Actions
3. Dokumentiere neue Tests gemÃ¤ÃŸ diesem Guide
